{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Market Data\n",
    "\n",
    "Market data (price and volume time series for each stock) will be used to benchmark the NLP models. This notebook retrieves the market data during the time period over which popularity data are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acelder/anaconda3/envs/py37/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract List of Stock Tickers\n",
    "\n",
    "The tickers available in the Robinhood popularity data provide a natural limit to the analysis. Each ticker available has an associated .csv file. Extract those tickers and store them in a flat .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_filenames = [file for file in os.walk(\"../../data/tabular/popularity_export\")][0][2]\n",
    "\n",
    "prog = re.compile(r'.csv')\n",
    "suffix_starts = {filename: prog.search(filename).start() for filename in ticker_filenames}\n",
    "ticker_names  = sorted([filename[:suffix] for filename, suffix in suffix_starts.items()\n",
    "                        if '_' not in filename])\n",
    "ticker_df = pd.DataFrame({'Ticker': ticker_names})\n",
    "ticker_df.to_csv('../../data/tabular/tickers.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Close Prices\n",
    "\n",
    "I'll use the yfinance library to call daily close prices from Yahoo Finance for each ticker. I don't want to get rate limited or blacklisted due to aggressive scraping (executed by yfinance under the hood) so to avoid this I'll set a 1 second delay after each ticker call. This will take about two hours to call every series. To make this process robust to errors I'll split it up by the first letter of each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a column corresponding to the first letter of each ticker.\n",
    "ticker_df['LeadingLetter'] = ticker_df['Ticker'].str.slice(0, 1)\n",
    "\n",
    "def get_letter_history(df, \n",
    "                       letter, \n",
    "                       directory='../../data/tabular/daily_price',\n",
    "                       start_date=pd.to_datetime('2017-01-01'), \n",
    "                       end_date=pd.to_datetime('2020-08-14'),\n",
    "                       verbose=True):\n",
    "    \n",
    "    tickers = ticker_df.loc[ticker_df.LeadingLetter == letter, 'Ticker']\n",
    "    \n",
    "    if verbose:\n",
    "        print('Downloading tickers starting with {}...'.format(letter))\n",
    "    \n",
    "    for i, ticker in tickers.iteritems():\n",
    "        ticker_yf = yf.Ticker(ticker)\n",
    "        ticker_yf.history(start=start_date, end=end_date).to_csv('{}/{}.csv'.format(directory, ticker))\n",
    "        if verbose:\n",
    "            print('\\t{}'.format(ticker))\n",
    "        \n",
    "    if verbose:\n",
    "        print('Daily price files for letter {} saved to {}'.format(letter, directory))\n",
    "    \n",
    "    time.sleep(1.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading B\n",
      "Downloading C\n",
      "Downloading D\n",
      "Downloading E\n",
      "Downloading F\n",
      "Downloading G\n",
      "Downloading H\n",
      "Downloading I\n",
      "Downloading J\n",
      "Downloading K\n",
      "Downloading L\n",
      "Downloading M\n",
      "Downloading N\n",
      "Downloading O\n",
      "Downloading P\n",
      "Downloading Q\n",
      "Downloading R\n",
      "Downloading S\n",
      "Downloading T\n",
      "Downloading U\n",
      "Downloading V\n",
      "Downloading W\n",
      "Downloading X\n",
      "Downloading Y\n",
      "Downloading Z\n"
     ]
    }
   ],
   "source": [
    "original_stdout = sys.stdout\n",
    "\n",
    "for letter in ticker_df.LeadingLetter.unique()[1:]:\n",
    "    print('Downloading {}'.format(letter))\n",
    "    \n",
    "    # save download log to text file\n",
    "    logfile = '../../log/download log {} - 2021-3-14.txt'.format(letter)\n",
    "    with open(logfile, 'w') as f:\n",
    "        sys.stdout = f\n",
    "        get_letter_history(ticker_df, letter)\n",
    "    sys.stdout = original_stdout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_2018 = pd.read_csv('../../data/tabular/wsb_posts/WSB Posts 2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
